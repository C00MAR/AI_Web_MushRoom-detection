{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision numpy matplotlib tensorboard kagglehub pillow scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import kagglehub\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = 64\n",
    "LEARNING_RATE = 0.002\n",
    "MAX_IMAGES_PER_CLASS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mushroom_data(max_images_per_class=1000):\n",
    "    print(\"Loading dataset...\")\n",
    "    \n",
    "    try:\n",
    "        path = kagglehub.dataset_download(\"zlatan599/mushroom1\")\n",
    "        print(f\"Dataset downloaded to: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Download error: {e}\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    train_csv = os.path.join(path, 'train.csv')\n",
    "    val_csv = os.path.join(path, 'val.csv')\n",
    "    \n",
    "    train_df = pd.read_csv(train_csv)\n",
    "    val_df = pd.read_csv(val_csv)\n",
    "    all_df = pd.concat([train_df, val_df], ignore_index=True)\n",
    "    \n",
    "    # Get top 10 classes\n",
    "    class_counts = all_df['label'].value_counts()\n",
    "    top10_classes = class_counts.head(10)\n",
    "    top10_class_names = list(top10_classes.index)\n",
    "    \n",
    "    print(f\"Selected top 10 classes with {max_images_per_class} images each\")\n",
    "    \n",
    "    class_to_idx = {class_name: i for i, class_name in enumerate(top10_class_names)}\n",
    "    \n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for class_name in top10_class_names:\n",
    "        class_df = all_df[all_df['label'] == class_name].copy()\n",
    "        class_df = class_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "        limited_df = class_df.head(max_images_per_class)\n",
    "        \n",
    "        for _, row in limited_df.iterrows():\n",
    "            img_path = row['image_path']\n",
    "            if img_path.startswith('/kaggle/working/'):\n",
    "                img_path = img_path.replace('/kaggle/working/', '')\n",
    "            \n",
    "            full_path = os.path.join(path, img_path)\n",
    "            if os.path.exists(full_path):\n",
    "                image_paths.append(full_path)\n",
    "                labels.append(class_to_idx[class_name])\n",
    "    \n",
    "    print(f\"Total images loaded: {len(image_paths):,}\")\n",
    "    \n",
    "    return image_paths, labels, top10_class_names, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MushroomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "            label = self.labels[idx]\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, label\n",
    "        except Exception:\n",
    "            dummy_image = torch.zeros(3, 64, 64)\n",
    "            return dummy_image, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MushroomCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 8 * 8, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths, labels, class_names, dataset_path = load_mushroom_data(MAX_IMAGES_PER_CLASS)\n",
    "\n",
    "if image_paths is None:\n",
    "    print(\"Failed to load data!\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = T.Compose([\n",
    "    T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    T.RandomApply([T.ColorJitter(hue=0.1)], p=0.8),\n",
    "    T.RandomVerticalFlip(p=0.5),\n",
    "    T.RandomRotation(degrees=360),\n",
    "    T.RandomApply([T.GaussianBlur(3, sigma=(0.1, 1.0))], p=0.3)\n",
    "])\n",
    "\n",
    "transform_test = T.Compose([\n",
    "    T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    image_paths, labels, test_size=0.3, random_state=42, stratify=labels\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Data split - Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MushroomDataset(X_train, y_train, transform_train)\n",
    "val_dataset = MushroomDataset(X_val, y_val, transform_test)\n",
    "test_dataset = MushroomDataset(X_test, y_test, transform_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MushroomCNN(num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        batch_size = y.size(0)\n",
    "        \n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_samples += batch_size\n",
    "        \n",
    "        preds = y_pred.argmax(1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = correct / total_samples\n",
    "    \n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "            \n",
    "            total_loss += loss.item() * y.size(0)\n",
    "            preds = y_pred.argmax(1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.0431, Test Accuracy: 0.2353\n",
      "New best model saved! (Val Acc: 0.2353)\n",
      "\n",
      "Epoch 2/15\n",
      "--------------------\n",
      "Test Loss: 1.8711, Test Accuracy: 0.2633\n",
      "New best model saved! (Val Acc: 0.2633)\n",
      "\n",
      "Epoch 3/15\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "print(\"Starting training...\")\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    print(\"-\" * 20)\n",
    "    \n",
    "    train_loss, train_acc = train(train_dataloader, model, criterion, optimizer, device)\n",
    "    val_loss, val_acc = test(val_dataloader, model, criterion, device)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/Train', train_acc, epoch)\n",
    "    writer.add_scalar('Loss/Val', val_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/Val', val_acc, epoch)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_mushroom_model.pth')\n",
    "        print(f\"New best model saved! (Val Acc: {val_acc:.4f})\")\n",
    "\n",
    "writer.close()\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_mushroom_model.pth'))\n",
    "print(\"Best model loaded for final evaluation\")\n",
    "\n",
    "final_loss, final_accuracy = test(test_dataloader, model, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_info(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"\\nModel information:\")\n",
    "    print(f\"  Total parameters: {total_params:,}\")\n",
    "    print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"  Model size: {total_params * 4 / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "print_model_info(model)\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"  Best validation accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"  Final test accuracy: {final_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "torch.save(model.state_dict(), 'mushroom_model_final.pth')\n",
    "print(\"✅ PyTorch model saved!\")\n",
    "\n",
    "dummy_input = torch.randn(1, 3, IMAGE_SIZE, IMAGE_SIZE, device=device)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    'mushroom_model.onnx',\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"✅ ONNX model exported to mushroom_model.onnx\")\n",
    "\n",
    "try:\n",
    "    import onnxruntime as ort\n",
    "    \n",
    "    ort_session = ort.InferenceSession('mushroom_model.onnx')\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: dummy_input.cpu().numpy()}\n",
    "    ort_outputs = ort_session.run(None, ort_inputs)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pytorch_output = model(dummy_input)\n",
    "    \n",
    "    print(f\"PyTorch prediction: {torch.argmax(pytorch_output, dim=1).item()}\")\n",
    "    print(f\"ONNX prediction: {np.argmax(ort_outputs[0], axis=1)[0]}\")\n",
    "    print(\"✅ ONNX verification successful!\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"💡 onnxruntime not installed - verification skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(model, test_loader, class_names, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = output.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_targets, all_preds, \n",
    "                              target_names=class_names, digits=4))\n",
    "\n",
    "analyze_results(model, test_dataloader, class_names, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
